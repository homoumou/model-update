{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c534af41",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0e52ebb4891d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#载入数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mtrans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./num'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m#mnist中的test_set一共有1万张照片，这里我们把前5000张用作validation_set,后5000张用作test_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./num'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             raise RuntimeError('Dataset not found.' +\n\u001b[0m\u001b[0;32m     91\u001b[0m                                ' You can use download=True to download it')\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import optim\n",
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from torchvision import datasets\n",
    "\n",
    "#载入数据\n",
    "trans = transforms.Compose((transforms.Resize((32,32)),transforms.ToTensor()))\n",
    "train_set = datasets.MNIST('./num',train=True,transform=trans, download=true)\n",
    "#mnist中的test_set一共有1万张照片，这里我们把前5000张用作validation_set,后5000张用作test_set\n",
    "val_set = list(datasets.MNIST('./num',train=False,transform=trans, download=true))[:5000]\n",
    "test_set = list(datasets.MNIST('./num',train=False,transform=trans, download=true))[5000:]\n",
    "\n",
    "train_loader = DataLoader(train_set,batch_size=150,shuffle=True)\n",
    "val_loader = DataLoader(val_set,batch_size=50,shuffle=True)\n",
    "test_loader = DataLoader(test_set,batch_size=50,shuffle=True)\n",
    "\n",
    "\n",
    "#构建resblock\n",
    "class resblock(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out,stride=1):\n",
    "        super(resblock,self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=stride,padding=1)\n",
    "        self.bn_1 = nn.BatchNorm2d(ch_out)\n",
    "        self.conv_2 = nn.Conv2d(ch_out,ch_out,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn_2 = nn.BatchNorm2d(ch_out)\n",
    "        self.ch_trans = nn.Sequential()\n",
    "        if ch_in != ch_out:\n",
    "            self.ch_trans = nn.Sequential(nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=stride),nn.BatchNorm2d(ch_out))\n",
    "        #ch_trans表示通道数转变。因为要做short_cut,所以x_pro和x_ch的size应该完全一致\n",
    "        \n",
    "    def  forward(self,x):\n",
    "        x_pro = F.relu(self.bn_1(self.conv_1(x)))\n",
    "        x_pro = self.bn_2(self.conv_2(x_pro))\n",
    "        \n",
    "        #short_cut:\n",
    "        x_ch = self.ch_trans(x)\n",
    "        out = x_pro + x_ch\n",
    "        out = F.relu(out)\n",
    "        return out \n",
    "    \n",
    "    \n",
    "#搭建resnet\n",
    "class Resnet18(nn.Module):\n",
    "    def __init__(self,num_class):\n",
    "        super(Resnet18,self).__init__()\n",
    "        self.conv_1 = nn.Sequential(\n",
    "        nn.Conv2d(1,16,kernel_size=3,stride=3,padding=0),\n",
    "        nn.BatchNorm2d(16))\n",
    "        self.block1 = resblock(16,32,1) \n",
    "        self.block2 = resblock(32,64,1) \n",
    "        self.block3 = resblock(64,128,2)\n",
    "        self.block4 = resblock(128,256,2)\n",
    "        self.outlayer = nn.Linear(256*3*3,num_class)#这个256*3*3是根据forward中x经过4个resblock之后来决定的\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = x.reshape(x.size(0),-1) #进行打平操作\n",
    "        result = self.outlayer(x)\n",
    "        return result       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fabbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = Resnet18(10).to(device) #模型初始化，10代表一共有10种类别\n",
    "print('模型需要训练的参数共有{}个'.format(sum(map(lambda p:p.numel(),model.parameters()))))\n",
    "loss_fn = nn.CrossEntropyLoss() #选择loss_function\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3) #选择优化方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc17a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate用于检测模型的预测效果，validation_set和test_set是同样的evaluate方法\n",
    "def evaluate(model,loader):\n",
    "    correct_num = 0\n",
    "    total_num = len(loader.dataset)\n",
    "    for img,label in loader: #lodaer中包含了很多batch，每个batch有32张图片\n",
    "        img,label = img.to(device),label.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(img)\n",
    "            pre_label = logits.argmax(dim=1)\n",
    "        correct_num += torch.eq(pre_label,label).sum().float().item()\n",
    "    \n",
    "    return correct_num/total_num \n",
    "\n",
    "\n",
    "\n",
    "best_epoch,best_acc = 0,0\n",
    "for epoch in range(10): #时间关系，我们只训练10个epoch\n",
    "    for batch_num,(img,label) in enumerate(train_loader):\n",
    "        #img.size [b,3,224,224]  label.size [b]\n",
    "        img,label = img.to(device),label.to(device)\n",
    "        logits = model(img)\n",
    "        loss = loss_fn(logits,label)\n",
    "        if (batch_num+1)%100 == 0:\n",
    "            print('这是第{}次迭代的第{}个batch,loss是{}'.format(epoch+1,batch_num+1,loss.item()))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch%2==0: #这里设置的是每训练两次epoch就进行一次validation\n",
    "        val_acc = evaluate(model,val_loader)\n",
    "        #如果val_acc比之前的好，那么就把该epoch保存下来，并把此时模型的参数保存到指定txt文件里\n",
    "        if val_acc>best_acc:\n",
    "            print('验证集上的准确率是：{}'.format(val_acc))\n",
    "            best_epoch = epoch\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(),'mnist_resnet_ckp.txt')\n",
    "    \n",
    "\n",
    "print('best_acc:{},best_epoch:{}'.format(best_acc,best_epoch))\n",
    "model.load_state_dict(torch.load('mnist_resnet_ckp.txt'))\n",
    "print('模型训练完毕，已将参数设置成训练过程中的最优值，现在开始测试test_set')\n",
    "\n",
    "test_acc = evaluate(model,test_loader)\n",
    "print('测试集上的准确率是：{}'.format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
